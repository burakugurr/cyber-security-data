
# Data Lakehouse using Cyber Security Data

  

# Project Information

  

We will create a sample lakehouse using Docker, execute an ETL process with Spark, and then access the data in the Iceberg table format from the Nessie Catalog.

  

## Architecture

![enter image description here](https://miro.medium.com/v2/resize:fit:828/format:webp/1*Qm158JhM06DwugNCoPe4pw.png)

  

# Pre-Requirements

1. Docker & Docker compose

2. Python 3.12

3. Spark 3.5.2(Scala: 2.12)

  

# Installations

  

1. ```pip install requirements.txt```

2. ``cd docker``

3. ```docker compose up ```


## Running Ports

|   Host| Port  |
| ------------ | ------------ |
|  Dremio | 9047  |
|  Nessie | 19120  |
|  MinIO | 9001  |


# Article

https://medium.com/towards-data-engineering/create-data-lakehouse-using-spark-iceberg-nessie-dremio-8d7a54855f13

